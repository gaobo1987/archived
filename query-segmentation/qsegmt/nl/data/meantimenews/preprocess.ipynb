{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this script converts xml files to NER format\n",
    "import os\n",
    "from lxml import etree\n",
    "\n",
    "\n",
    "class Entity:\n",
    "    def __init__(self, _id, _type, _description):\n",
    "        self.id = _id\n",
    "        self.type = _type\n",
    "        self.description = _description\n",
    "\n",
    "        \n",
    "        \n",
    "class Token:\n",
    "    def __init__(self, _id, _sent_id, _text, _ent_iob='O', _ent_type=''):\n",
    "        self.id = _id\n",
    "        self.sent_id = _sent_id\n",
    "        self.text = _text\n",
    "        self.ent_iob = _ent_iob\n",
    "        self.ent_type = _ent_type\n",
    "        \n",
    "    def json(self):\n",
    "        return {\n",
    "            'id': self.id,\n",
    "            'sentence_id': self.sent_id,\n",
    "            'text': self.text,\n",
    "            'entity_iob': self.ent_iob,\n",
    "            'entity_type': self.ent_type\n",
    "        }\n",
    "    \n",
    "\n",
    "def parse_xml_to_ner_format(doc_path, output_writer, verbose=False):\n",
    "    tree = etree.parse(doc_path)\n",
    "    # parse tokens\n",
    "    token_tags = tree.findall('token')\n",
    "    token_map = {}\n",
    "    tokens = []\n",
    "    for t in token_tags:\n",
    "        sent_id = t.get('sentence')\n",
    "        token_id = t.get('t_id')\n",
    "        text = t.text\n",
    "        if verbose:\n",
    "            print(sent_id, token_id, text)\n",
    "        token = Token(token_id, sent_id, text)\n",
    "        token_map[token_id] = token\n",
    "        tokens.append(token)\n",
    "        \n",
    "    # parse entities\n",
    "    markables = tree.find('Markables')\n",
    "    entities = {}\n",
    "    for m in markables:\n",
    "        if m.tag == 'ENTITY':\n",
    "            ent_id = m.get('m_id')\n",
    "            ent_type = m.get('ent_type')\n",
    "            ent_description = m.get('TAG_DESCRIPTOR')\n",
    "            if ent_type is not None and ent_type != '':\n",
    "                e = Entity(ent_id, ent_type, ent_description)\n",
    "                entities[ent_id] = e\n",
    "    if verbose:\n",
    "        print('Entities: ')\n",
    "        for e_id in entities.keys():\n",
    "            print(e_id, entities[e_id].type, entities[e_id].description)\n",
    "            \n",
    "    # parse entity-mentions\n",
    "    mentions = markables.findall('ENTITY_MENTION')\n",
    "    mentioned_tokens = {}\n",
    "    for m in mentions:\n",
    "        m_id = m.get('m_id')\n",
    "        mentioned_tokens[m_id] = []\n",
    "        for t in m.findall('token_anchor'):\n",
    "            mentioned_tokens[m_id].append(t.get('t_id'))\n",
    "        mentioned_tokens[m_id] = sorted(mentioned_tokens[m_id])\n",
    "        \n",
    "    # update token ner tags\n",
    "    relations = tree.find('Relations')\n",
    "    referrals = relations.findall('REFERS_TO')\n",
    "    for r in referrals:\n",
    "        target = r.find('target')\n",
    "        ent_id = target.get('m_id')\n",
    "        if ent_id in entities:\n",
    "            sources = r.findall('source')\n",
    "            ent = entities[ent_id]\n",
    "            if verbose:\n",
    "                print(ent.type, ent.description)\n",
    "            entity_type = ent.type \n",
    "            source_token_ids = []\n",
    "            for s in sources:\n",
    "                e_mention_id = s.get('m_id')            \n",
    "                if e_mention_id in mentioned_tokens:\n",
    "                    source_token_ids.extend(mentioned_tokens[e_mention_id])\n",
    "\n",
    "            source_token_ids = list(set(source_token_ids))\n",
    "            int_source_token_ids = sorted([int(i) for i in source_token_ids])\n",
    "            source_token_ids = list([str(i) for i in int_source_token_ids])\n",
    "            if verbose:\n",
    "                print('--------------------------------------------------')\n",
    "            cur_sent_id = None\n",
    "            for tid in source_token_ids:\n",
    "                token = token_map[tid]\n",
    "                new_sent_bool = (cur_sent_id != token.sent_id)\n",
    "                entity_iob = 'I'\n",
    "                if new_sent_bool:\n",
    "                    cur_sent_id = token.sent_id\n",
    "                    entity_iob = 'B'\n",
    "                token.ent_iob = entity_iob\n",
    "                token.ent_type = entity_type\n",
    "                if verbose:\n",
    "                    print(token.json())\n",
    "            if verbose:\n",
    "                print('--------------------------------------------------')\n",
    "        \n",
    "    # write tokens to output\n",
    "    cur_sent_id = None\n",
    "    for t in tokens:\n",
    "        if cur_sent_id != t.sent_id:\n",
    "            output_writer.write('\\n')\n",
    "            cur_sent_id = t.sent_id\n",
    "\n",
    "        ent = t.ent_iob if t.ent_iob == 'O' else t.ent_iob + '-' + t.ent_type\n",
    "        output_writer.write(t.text + ' ' + ent + '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 Amerikaanse\n",
      "0 2 beurzen\n",
      "0 3 stijgen\n",
      "0 4 vierde\n",
      "0 5 opeenvolgende\n",
      "0 6 week\n",
      "1 7 04-Apr-09\n",
      "2 8 Op\n",
      "2 9 vrijdag\n",
      "2 10 noteerden\n",
      "2 11 de\n",
      "2 12 Amerikaanse\n",
      "2 13 beursindexen\n",
      "2 14 opnieuw\n",
      "2 15 een\n",
      "2 16 stijging\n",
      "2 17 ,\n",
      "2 18 waarmee\n",
      "2 19 een\n",
      "2 20 positieve\n",
      "2 21 periode\n",
      "2 22 van\n",
      "2 23 vier\n",
      "2 24 weken\n",
      "2 25 is\n",
      "2 26 neergezet\n",
      "2 27 .\n",
      "3 28 Dit\n",
      "3 29 ondanks\n",
      "3 30 een\n",
      "3 31 rapport\n",
      "3 32 dat\n",
      "3 33 diezelfde\n",
      "3 34 dag\n",
      "3 35 door\n",
      "3 36 het\n",
      "3 37 Amerikaanse\n",
      "3 38 ministerie\n",
      "3 39 van\n",
      "3 40 werkgelegenheid\n",
      "3 41 werd\n",
      "3 42 gepubliceerd\n",
      "3 43 en\n",
      "3 44 waarin\n",
      "3 45 werd\n",
      "3 46 gemeld\n",
      "3 47 dat\n",
      "3 48 de\n",
      "3 49 Amerikaanse\n",
      "3 50 economie\n",
      "3 51 in\n",
      "3 52 maart\n",
      "3 53 663.000\n",
      "3 54 banen\n",
      "3 55 was\n",
      "3 56 kwijtgeraakt\n",
      "3 57 en\n",
      "3 58 de\n",
      "3 59 werkeloosheid\n",
      "3 60 was\n",
      "3 61 gestegen\n",
      "3 62 tot\n",
      "3 63 8,5\n",
      "3 64 %\n",
      "3 65 ,\n",
      "3 66 het\n",
      "3 67 hoogste\n",
      "3 68 cijfer\n",
      "3 69 sinds\n",
      "3 70 1983\n",
      "3 71 .\n",
      "4 72 De\n",
      "4 73 Dow\n",
      "4 74 Jones\n",
      "4 75 Industrial\n",
      "4 76 Average\n",
      "4 77 noteerde\n",
      "4 78 een\n",
      "4 79 lichte\n",
      "4 80 stijging\n",
      "4 81 van\n",
      "4 82 een\n",
      "4 83 half\n",
      "4 84 procent\n",
      "4 85 of\n",
      "4 86 39\n",
      "4 87 punten\n",
      "4 88 en\n",
      "4 89 sloot\n",
      "4 90 de\n",
      "4 91 dag\n",
      "4 92 af\n",
      "4 93 op\n",
      "4 94 8.017\n",
      "4 95 .\n",
      "5 96 Deze\n",
      "5 97 index\n",
      "5 98 is\n",
      "5 99 sinds\n",
      "5 100 februari\n",
      "5 101 geen\n",
      "5 102 dag\n",
      "5 103 meer\n",
      "5 104 boven\n",
      "5 105 de\n",
      "5 106 8.000\n",
      "5 107 geÃ«indigd\n",
      "5 108 .\n",
      "6 109 De\n",
      "6 110 Dow\n",
      "6 111 steeg\n",
      "6 112 voor\n",
      "6 113 de\n",
      "6 114 laatste\n",
      "6 115 keer\n",
      "6 116 vier\n",
      "6 117 weken\n",
      "6 118 achter\n",
      "6 119 elkaar\n",
      "6 120 tussen\n",
      "6 121 september\n",
      "6 122 en\n",
      "6 123 oktober\n",
      "6 124 2007\n",
      "6 125 ,\n",
      "6 126 toen\n",
      "6 127 een\n",
      "6 128 absoluut\n",
      "6 129 hoogtepunt\n",
      "6 130 van\n",
      "6 131 meer\n",
      "6 132 dan\n",
      "6 133 14.000\n",
      "6 134 werd\n",
      "6 135 bereikt\n",
      "6 136 .\n",
      "7 137 Dit\n",
      "7 138 is\n",
      "7 139 de\n",
      "7 140 beste\n",
      "7 141 winstperiode\n",
      "7 142 van\n",
      "7 143 de\n",
      "7 144 index\n",
      "7 145 sinds\n",
      "7 146 1993\n",
      "7 147 .\n",
      "8 148 De\n",
      "8 149 bredere\n",
      "8 150 S\n",
      "8 151 &\n",
      "8 152 P\n",
      "8 153 500\n",
      "8 154 steeg\n",
      "8 155 acht\n",
      "8 156 punten\n",
      "8 157 of\n",
      "8 158 1\n",
      "8 159 procent\n",
      "8 160 voor\n",
      "8 161 sluiting\n",
      "8 162 .\n",
      "9 163 De\n",
      "9 164 Nasdaq\n",
      "9 165 Composite\n",
      "9 166 behaalde\n",
      "9 167 met\n",
      "9 168 1,2\n",
      "9 169 %\n",
      "9 170 de\n",
      "9 171 grootste\n",
      "9 172 winst\n",
      "9 173 van\n",
      "9 174 de\n",
      "9 175 drie\n",
      "9 176 en\n",
      "9 177 sloot\n",
      "9 178 op\n",
      "9 179 1.622\n",
      "9 180 .\n",
      "10 181 Zowel\n",
      "10 182 de\n",
      "10 183 S\n",
      "10 184 &\n",
      "10 185 P\n",
      "10 186 als\n",
      "10 187 de\n",
      "10 188 Dow\n",
      "10 189 stegen\n",
      "10 190 3\n",
      "10 191 %\n",
      "10 192 in\n",
      "10 193 de\n",
      "10 194 loop\n",
      "10 195 van\n",
      "10 196 de\n",
      "10 197 week\n",
      "10 198 en\n",
      "10 199 de\n",
      "10 200 Nasdaq\n",
      "10 201 zette\n",
      "10 202 een\n",
      "10 203 winst\n",
      "10 204 neer\n",
      "10 205 van\n",
      "10 206 bijna\n",
      "10 207 5\n",
      "10 208 %\n",
      "10 209 .\n",
      "11 210 De\n",
      "11 211 Duitse\n",
      "11 212 DAX\n",
      "11 213 en\n",
      "11 214 de\n",
      "11 215 Japanse\n",
      "11 216 Nikkei\n",
      "11 217 225\n",
      "11 218 bleven\n",
      "11 219 gelijk\n",
      "11 220 staan\n",
      "11 221 terwijl\n",
      "11 222 de\n",
      "11 223 Britse\n",
      "11 224 FTSE\n",
      "11 225 100\n",
      "11 226 daalde\n",
      "11 227 met\n",
      "11 228 2,3\n",
      "11 229 %\n",
      "11 230 .\n",
      "Entities: \n",
      "64 FIN hoogste cijfer\n",
      "65 PRO de werkeloosheid\n",
      "66 PRO 663.000 banen\n",
      "178 FIN US stock market indexes\n",
      "179 ORG United States Department of Labor\n",
      "180 FIN Economy of the United States\n",
      "190 FIN S&P 500\n",
      "181 FIN Dow Jones Industrial Average\n",
      "189 FIN NASDAQ Index (NASDAQ composite)\n",
      "177 LOC United States of America \n",
      "188 FIN NIKKEI\n",
      "ORG United States Department of Labor\n",
      "--------------------------------------------------\n",
      "{'id': '36', 'sentence_id': '3', 'text': 'het', 'entity_iob': 'B', 'entity_type': 'ORG'}\n",
      "{'id': '37', 'sentence_id': '3', 'text': 'Amerikaanse', 'entity_iob': 'I', 'entity_type': 'ORG'}\n",
      "{'id': '38', 'sentence_id': '3', 'text': 'ministerie', 'entity_iob': 'I', 'entity_type': 'ORG'}\n",
      "{'id': '39', 'sentence_id': '3', 'text': 'van', 'entity_iob': 'I', 'entity_type': 'ORG'}\n",
      "{'id': '40', 'sentence_id': '3', 'text': 'werkgelegenheid', 'entity_iob': 'I', 'entity_type': 'ORG'}\n",
      "--------------------------------------------------\n",
      "FIN S&P 500\n",
      "--------------------------------------------------\n",
      "{'id': '148', 'sentence_id': '8', 'text': 'De', 'entity_iob': 'B', 'entity_type': 'FIN'}\n",
      "{'id': '149', 'sentence_id': '8', 'text': 'bredere', 'entity_iob': 'I', 'entity_type': 'FIN'}\n",
      "{'id': '150', 'sentence_id': '8', 'text': 'S', 'entity_iob': 'I', 'entity_type': 'FIN'}\n",
      "{'id': '151', 'sentence_id': '8', 'text': '&', 'entity_iob': 'I', 'entity_type': 'FIN'}\n",
      "{'id': '152', 'sentence_id': '8', 'text': 'P', 'entity_iob': 'I', 'entity_type': 'FIN'}\n",
      "{'id': '153', 'sentence_id': '8', 'text': '500', 'entity_iob': 'I', 'entity_type': 'FIN'}\n",
      "{'id': '182', 'sentence_id': '10', 'text': 'de', 'entity_iob': 'B', 'entity_type': 'FIN'}\n",
      "{'id': '183', 'sentence_id': '10', 'text': 'S', 'entity_iob': 'I', 'entity_type': 'FIN'}\n",
      "{'id': '184', 'sentence_id': '10', 'text': '&', 'entity_iob': 'I', 'entity_type': 'FIN'}\n",
      "{'id': '185', 'sentence_id': '10', 'text': 'P', 'entity_iob': 'I', 'entity_type': 'FIN'}\n",
      "--------------------------------------------------\n",
      "FIN hoogste cijfer\n",
      "--------------------------------------------------\n",
      "{'id': '66', 'sentence_id': '3', 'text': 'het', 'entity_iob': 'B', 'entity_type': 'FIN'}\n",
      "{'id': '67', 'sentence_id': '3', 'text': 'hoogste', 'entity_iob': 'I', 'entity_type': 'FIN'}\n",
      "{'id': '68', 'sentence_id': '3', 'text': 'cijfer', 'entity_iob': 'I', 'entity_type': 'FIN'}\n",
      "--------------------------------------------------\n",
      "PRO de werkeloosheid\n",
      "--------------------------------------------------\n",
      "{'id': '58', 'sentence_id': '3', 'text': 'de', 'entity_iob': 'B', 'entity_type': 'PRO'}\n",
      "{'id': '59', 'sentence_id': '3', 'text': 'werkeloosheid', 'entity_iob': 'I', 'entity_type': 'PRO'}\n",
      "--------------------------------------------------\n",
      "PRO 663.000 banen\n",
      "--------------------------------------------------\n",
      "{'id': '53', 'sentence_id': '3', 'text': '663.000', 'entity_iob': 'B', 'entity_type': 'PRO'}\n",
      "{'id': '54', 'sentence_id': '3', 'text': 'banen', 'entity_iob': 'I', 'entity_type': 'PRO'}\n",
      "--------------------------------------------------\n",
      "FIN US stock market indexes\n",
      "--------------------------------------------------\n",
      "{'id': '1', 'sentence_id': '0', 'text': 'Amerikaanse', 'entity_iob': 'B', 'entity_type': 'FIN'}\n",
      "{'id': '2', 'sentence_id': '0', 'text': 'beurzen', 'entity_iob': 'I', 'entity_type': 'FIN'}\n",
      "{'id': '11', 'sentence_id': '2', 'text': 'de', 'entity_iob': 'B', 'entity_type': 'FIN'}\n",
      "{'id': '12', 'sentence_id': '2', 'text': 'Amerikaanse', 'entity_iob': 'I', 'entity_type': 'FIN'}\n",
      "{'id': '13', 'sentence_id': '2', 'text': 'beursindexen', 'entity_iob': 'I', 'entity_type': 'FIN'}\n",
      "--------------------------------------------------\n",
      "LOC United States of America \n",
      "--------------------------------------------------\n",
      "{'id': '1', 'sentence_id': '0', 'text': 'Amerikaanse', 'entity_iob': 'B', 'entity_type': 'LOC'}\n",
      "{'id': '12', 'sentence_id': '2', 'text': 'Amerikaanse', 'entity_iob': 'B', 'entity_type': 'LOC'}\n",
      "{'id': '37', 'sentence_id': '3', 'text': 'Amerikaanse', 'entity_iob': 'B', 'entity_type': 'LOC'}\n",
      "{'id': '49', 'sentence_id': '3', 'text': 'Amerikaanse', 'entity_iob': 'I', 'entity_type': 'LOC'}\n",
      "--------------------------------------------------\n",
      "FIN Economy of the United States\n",
      "--------------------------------------------------\n",
      "{'id': '48', 'sentence_id': '3', 'text': 'de', 'entity_iob': 'B', 'entity_type': 'FIN'}\n",
      "{'id': '49', 'sentence_id': '3', 'text': 'Amerikaanse', 'entity_iob': 'I', 'entity_type': 'FIN'}\n",
      "{'id': '50', 'sentence_id': '3', 'text': 'economie', 'entity_iob': 'I', 'entity_type': 'FIN'}\n",
      "--------------------------------------------------\n",
      "FIN Dow Jones Industrial Average\n",
      "--------------------------------------------------\n",
      "{'id': '72', 'sentence_id': '4', 'text': 'De', 'entity_iob': 'B', 'entity_type': 'FIN'}\n",
      "{'id': '73', 'sentence_id': '4', 'text': 'Dow', 'entity_iob': 'I', 'entity_type': 'FIN'}\n",
      "{'id': '74', 'sentence_id': '4', 'text': 'Jones', 'entity_iob': 'I', 'entity_type': 'FIN'}\n",
      "{'id': '75', 'sentence_id': '4', 'text': 'Industrial', 'entity_iob': 'I', 'entity_type': 'FIN'}\n",
      "{'id': '76', 'sentence_id': '4', 'text': 'Average', 'entity_iob': 'I', 'entity_type': 'FIN'}\n",
      "{'id': '96', 'sentence_id': '5', 'text': 'Deze', 'entity_iob': 'B', 'entity_type': 'FIN'}\n",
      "{'id': '97', 'sentence_id': '5', 'text': 'index', 'entity_iob': 'I', 'entity_type': 'FIN'}\n",
      "{'id': '109', 'sentence_id': '6', 'text': 'De', 'entity_iob': 'B', 'entity_type': 'FIN'}\n",
      "{'id': '110', 'sentence_id': '6', 'text': 'Dow', 'entity_iob': 'I', 'entity_type': 'FIN'}\n",
      "{'id': '143', 'sentence_id': '7', 'text': 'de', 'entity_iob': 'B', 'entity_type': 'FIN'}\n",
      "{'id': '144', 'sentence_id': '7', 'text': 'index', 'entity_iob': 'I', 'entity_type': 'FIN'}\n",
      "{'id': '187', 'sentence_id': '10', 'text': 'de', 'entity_iob': 'B', 'entity_type': 'FIN'}\n",
      "{'id': '188', 'sentence_id': '10', 'text': 'Dow', 'entity_iob': 'I', 'entity_type': 'FIN'}\n",
      "--------------------------------------------------\n",
      "FIN NIKKEI\n",
      "--------------------------------------------------\n",
      "{'id': '214', 'sentence_id': '11', 'text': 'de', 'entity_iob': 'B', 'entity_type': 'FIN'}\n",
      "{'id': '215', 'sentence_id': '11', 'text': 'Japanse', 'entity_iob': 'I', 'entity_type': 'FIN'}\n",
      "{'id': '216', 'sentence_id': '11', 'text': 'Nikkei', 'entity_iob': 'I', 'entity_type': 'FIN'}\n",
      "{'id': '217', 'sentence_id': '11', 'text': '225', 'entity_iob': 'I', 'entity_type': 'FIN'}\n",
      "--------------------------------------------------\n",
      "FIN NASDAQ Index (NASDAQ composite)\n",
      "--------------------------------------------------\n",
      "{'id': '163', 'sentence_id': '9', 'text': 'De', 'entity_iob': 'B', 'entity_type': 'FIN'}\n",
      "{'id': '164', 'sentence_id': '9', 'text': 'Nasdaq', 'entity_iob': 'I', 'entity_type': 'FIN'}\n",
      "{'id': '165', 'sentence_id': '9', 'text': 'Composite', 'entity_iob': 'I', 'entity_type': 'FIN'}\n",
      "{'id': '199', 'sentence_id': '10', 'text': 'de', 'entity_iob': 'B', 'entity_type': 'FIN'}\n",
      "{'id': '200', 'sentence_id': '10', 'text': 'Nasdaq', 'entity_iob': 'I', 'entity_type': 'FIN'}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "output_writer = open('all.txt', 'w')\n",
    "doc_path = os.path.join('intra_cross_doc_annotations', 'corpus_stock', '124259_US_stocks_log_gains_for_fourth_week_in_a_row.xml')\n",
    "parse_xml_to_ner_format(doc_path, output_writer, True)\n",
    "output_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...in  corpus_stock\n",
      "parsing  124259_US_stocks_log_gains_for_fourth_week_in_a_row.xml\n",
      "parsing  62405_Sub-prime_lenders_send_jitters_through_global_markets.xml\n",
      "parsing  251007_Japanese_stocks_continue_to_fall_after_earthquake.xml\n",
      "parsing  116834_Japan_enters_recession.xml\n",
      "parsing  121416_US_stock_markets_fall_to_lowest_levels_since_1997.xml\n",
      "parsing  113219_Stock_markets_worldwide_fall_dramatically.xml\n",
      "parsing  96770_World_stocks_plunge_on_fears_on_US_recession.xml\n",
      "parsing  114864_Global_markets_plunge.xml\n",
      "parsing  82738_US_stock_markets_tumble.xml\n",
      "parsing  113330_Shares_worldwide_surge_due_to_US_government_plan.xml\n",
      "parsing  121225_Dow_Jones_Industrial_Average_closes_at_lowest_level_in_six_years.xml\n",
      "parsing  131162_Stock_markets_worldwide_rise_on_hopes_of_US_economic_recovery.xml\n",
      "parsing  112579_Dow_falls_340_points_amid_unemployment_and_retail_sales_rates_news.xml\n",
      "parsing  115064_Global_markets_surge_in_value.xml\n",
      "parsing  114904_Dow_Jones_recovers_hundreds_of_points,_before_losing_them_in_minutes.xml\n",
      "parsing  76437_Markets_dragged_down_by_credit_crisis.xml\n",
      "parsing  122475_US_stock_markets_have_their_best_week_since_November.xml\n",
      "parsing  121978_US_stock_markets_reach_12-year_lows.xml\n",
      "parsing  113278_Markets_rally_as_world_central_banks_infuse_cash.xml\n",
      "parsing  113227_Russian_stock_markets_suspended_amid_market_turmoil.xml\n",
      "parsing  115587_Global_stock_markets_plunge.xml\n",
      "parsing  113267_Russian_markets_to_remain_closed_until_Friday.xml\n",
      "parsing  115711_Asian_stock_markets_slide.xml\n",
      "parsing  141225_British_FTSE_index_reaches_one-year_high,_other_European_markets_rise.xml\n",
      "parsing  114613_Stock_markets_worldwide_continue_to_fall.xml\n",
      "parsing  141483_Bank_of_America_reports_losses.xml\n",
      "parsing  61327_U.S._stocks_plummet_amid_global_sell-off.xml\n",
      "parsing  114565_Worldwide_markets_fall_precipitously.xml\n",
      "parsing  114719_Markets_down_across_the_world.xml\n",
      "parsing  180695_US_stocks_see_9%_drop_before_making_recovery.xml\n",
      "...in  corpus_gm\n",
      "parsing  127461_Penske_Auto_selected_to_buy_General_Motors.xml\n",
      "parsing  31706_Ford_Motor_Company_cutting_30,000_jobs_by_2012.xml\n",
      "parsing  123881_GM_and_Chrysler_receive_Canadian_loans_amid_US_restructuring_ultimata.xml\n",
      "parsing  47720_Ford_announces_deep_production_cuts_in_response_to_growing_losses.xml\n",
      "parsing  126878_Bankruptcy_for_U.S._automaker_GM_becomes_almost_certain_after_bondholder_offers_fail.xml\n",
      "parsing  118147_US_automaker_bailout_deal_fails_to_pass_Senate.xml\n",
      "parsing  126361_U.S._automaker_GM_plans_to_close_1,100_dealerships.xml\n",
      "parsing  39951_Australian_government_announces_52.5_million_financial_assistance_package_for_Ford.xml\n",
      "parsing  60658_DaimlerChrysler_plans_to_cut_13,000_jobs.xml\n",
      "parsing  160257_Ford_US_auto_sales_spike.xml\n",
      "parsing  127226_U.S._manufacturer_General_Motors_seeks_bankruptcy_protection.xml\n",
      "parsing  124043_General_Motors_automobile_sales_plunge_by_45%.xml\n",
      "parsing  60086_Ford_Taurus_to_be_revived.xml\n",
      "parsing  125796_Chrysler_files_for_bankruptcy,_Fiat_Group_SpA_to_run_company.xml\n",
      "parsing  120578_Automobile_sales_in_the_United_States_down_sharply.xml\n",
      "parsing  126311_U.S._automaker_Chrysler_wants_to_eliminate_789_dealerships.xml\n",
      "parsing  120554_GM,_Chrysler_offer_buyouts_and_early_retirement_to_workers.xml\n",
      "parsing  121134_US_automakers_GM_and_Chrysler_seek_more_government_aid.xml\n",
      "parsing  79240_Ford_offers_78_million_for_Romanian_auto_plant.xml\n",
      "parsing  150433_Ford_Motors_posts_2.7_billion_annual_profit.xml\n",
      "parsing  31965_GM_posts_first_annual_loss_since_1992.xml\n",
      "parsing  143480_Automaker_GM_to_cut_10,000_jobs_at_Opel.xml\n",
      "parsing  264435_Fiat_plans_to_buy_majority_stake_in_Chrysler.xml\n",
      "parsing  126029_US_automaker_GM_reports_losses.xml\n",
      "parsing  1007169_Mary_Barra_appointed_as_General_Motors_chief.xml\n",
      "parsing  118175_White_House_considering_auto_rescue_plan.xml\n",
      "parsing  68899_DaimlerChrysler_to_sell_Chrysler_Group.xml\n",
      "parsing  127227_Barack_Obama_presents_rescue_plan_after_GM_declaration_of_bankruptcy.xml\n",
      "parsing  143300_Automobile_manufacturer_Ford_posts_unexpected_profits.xml\n",
      "parsing  127248_CEO_of_GM_outlines_plan.xml\n",
      "...in  corpus_airbus\n",
      "parsing  276079_Boeing_rolls_out_first_787_Dreamliner_to_go_into_service.xml\n",
      "parsing  4764_Boeing_unveils_long-range_777.xml\n",
      "parsing  128016_China_Eastern_Airlines_to_purchase_twenty_new_Airbus_A320_jets.xml\n",
      "parsing  25501_Engine_troubles_delay_Airbus_superjumbo_tour.xml\n",
      "parsing  8951_World_largest_passenger_airliner_makes_first_flight.xml\n",
      "parsing  3307_Airbus_launches_world_largest_passenger_plane.xml\n",
      "parsing  145930_Boeing_787_Dreamliner_makes_maiden_flight.xml\n",
      "parsing  62929_A380_makes_maiden_flight_to_US.xml\n",
      "parsing  108294_Government_Accountability_Office_requests_rerun_of_US_Air_Force_tanker_bid.xml\n",
      "parsing  82548_First_Airbus_A380_delivered.xml\n",
      "parsing  102977_Airbus_parent_EADS_wins_13_billion_UK_RAF_airtanker_contract.xml\n",
      "parsing  73808_Boeing_unveils_new_787_Dreamliner.xml\n",
      "parsing  3835_Chinese_airlines_agree_purchase_of_Boeing_787_Dreamliners.xml\n",
      "parsing  71526_Aeroflot_negotiates_purchase_of_22_new_Boeing_787_Dreamliner_aircraft.xml\n",
      "parsing  129865_Airbus_offers_funding_to_search_for_black_boxes_from_Air_France_disaster.xml\n",
      "parsing  11716_Airbus_wins_Qatar_Airways_order_worth_15bn.xml\n",
      "parsing  106653_Boeing_pushes_back_737_replacement_development.xml\n",
      "parsing  11714_Ryanair_exercises_options_on_five_Boeing_737s.xml\n",
      "parsing  82597_First_A380_enters_commercial_service.xml\n",
      "parsing  51682_Singapore_Airlines_to_be_compensated_for_A380_delays.xml\n",
      "parsing  149731_Technical_problem_on_Airbus_A400M_maiden_flight.xml\n",
      "parsing  61389_Airbus_announces_job_cuts_of_10,000.xml\n",
      "parsing  100911_Northrop_Grumman_and_Airbus_parent_EADS_defeat_Boeing.xml\n",
      "parsing  1173_Internal_emails_expose_Boeing-Air_Force_contract_discussions.xml\n",
      "parsing  87805_Indonesia_transport_minister.xml\n",
      "parsing  41882_Boeing_delivers_final_717_to_AirTran,_ending_Douglas_era.xml\n",
      "parsing  8983_Boeing_secures_11bn_of_aircraft_deals.xml\n",
      "parsing  71426_Aer_Lingus_buys_twelve_new_long-haul_Airbus_jets.xml\n",
      "parsing  5403_Boeing_allowed_to_bid_for_U.S._space_launch_contracts_again.xml\n",
      "parsing  78496_Airbus_A380_test_flight_delayed_after_accident.xml\n",
      "...in  corpus_apple\n",
      "parsing  23468_Apple_plans_another_special_event.xml\n",
      "parsing  58207_Apple_introduces_iPhone_and_Apple_TV.xml\n",
      "parsing  101354_Apple_releases_iPhone_SDK,_announces_upcoming_update.xml\n",
      "parsing  60083_Apple_Corps_resolve.xml\n",
      "parsing  40203_Apple_Corps_loses.xml\n",
      "parsing  21302_Apple_unveils_iPod_nano.xml\n",
      "parsing  89284_Apple_to_lower_UK_iTunes_prices.xml\n",
      "parsing  191597_Apple_swamped_by_iPhone.xml\n",
      "parsing  43503_Apple_plans_to_sell.xml\n",
      "parsing  37961_Apple_releases_program.xml\n",
      "parsing  58772_Apple_Inc_doubled.xml\n",
      "parsing  23973_Apple_introduces_new_iPod_with_video_playback_capabilities.xml\n",
      "parsing  10450_Apple_Computer_CEO.xml\n",
      "parsing  30414_Apple_unveils_new_Intel-based_Mac.xml\n",
      "parsing  78899_Apple_announces_new_iPod_range.xml\n",
      "parsing  107785_Apple_launches_3G.xml\n",
      "parsing  127576_Apple_launches_new.xml\n",
      "parsing  265977_Apple_announces_Mac_OS_X_Lion,_iOS_5,_and_iCloud.xml\n",
      "parsing  238039_Apple_Inc._CEO_Steve_Jobs_on_medical_leave.xml\n",
      "parsing  58383_Cisco_sues_Apple.xml\n",
      "parsing  40986_Apple_releases_Macbook.xml\n",
      "parsing  9549_Reactions_to_Apple.xml\n",
      "parsing  190356_Apple_unveils_iPhone_4.xml\n",
      "parsing  103623_Apples_iTunes_replaces.xml\n",
      "parsing  199629_Apple_executive_leaves.xml\n",
      "parsing  37313_Beatles_Apple_Corps.xml\n",
      "parsing  279494_Apple_executive_Steve.xml\n",
      "parsing  287096_Apple_Inc_co_founder.xml\n",
      "parsing  195869_Apple_to_give_free_cases.xml\n",
      "parsing  214601_Apple_unveils_new_MacBook_Air_laptops.xml\n"
     ]
    }
   ],
   "source": [
    "# composing all.txt\n",
    "import os\n",
    "parent_dir = 'with_original_labels'\n",
    "output_writer = open(os.path.join(parent_dir, 'all.txt'), 'w')\n",
    "parent_dir = os.path.join('intra_cross_doc_annotations')\n",
    "subdirs = os.listdir(parent_dir)\n",
    "for sub in subdirs:\n",
    "    print('...in ', sub)\n",
    "    doc_annotations_path = os.path.join(parent_dir, sub)\n",
    "    subsubs = os.listdir(doc_annotations_path)\n",
    "    for f in subsubs:\n",
    "        ftype = f[-3:]\n",
    "        if ftype == 'xml':\n",
    "            print('parsing ', f)\n",
    "            doc_path = os.path.join(doc_annotations_path, f)\n",
    "            parse_xml_to_ner_format(doc_path, output_writer)\n",
    "\n",
    "output_writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I-FIN', 'B-PER', 'I-PRO', 'I-ORG', 'B-PRO', 'B-FIN', 'B-ORG', 'O', 'I-LOC', 'I-PER', 'B-LOC'}\n"
     ]
    }
   ],
   "source": [
    "# available ner tags\n",
    "f = open(os.path.join(parent_dir, 'all.txt'), 'r')\n",
    "s = set()\n",
    "for l in f:\n",
    "    if l != '\\n':\n",
    "        second = l[:-1].split(' ')[1]\n",
    "        s.add(second)\n",
    "f.close()\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_sents:  1786\n",
      "num_train:  1250\n",
      "num_test:  536\n"
     ]
    }
   ],
   "source": [
    "# split all.txt into train.txt (70%) and test.txt (30%)\n",
    "import random\n",
    "\n",
    "f = open(os.path.join(parent_dir, 'all.txt'), 'r')\n",
    "sentences = []\n",
    "sent = []\n",
    "lines = f.readlines()\n",
    "num_sents = 0\n",
    "for l in lines:\n",
    "    if l == '\\n':\n",
    "        num_sents += 1\n",
    "\n",
    "num_train = int(num_sents * 0.7)\n",
    "\n",
    "for l in lines:\n",
    "    if l == '\\n' and len(sent) > 0:\n",
    "        sentences.append(sent.copy())\n",
    "        sent = []\n",
    "    elif l != '\\n':\n",
    "        sent.append(l[:-1])\n",
    "\n",
    "print('num_sents: ', num_sents)\n",
    "print('num_train: ', num_train)\n",
    "print('num_test: ', num_sents - num_train)\n",
    "random.shuffle(sentences)     \n",
    "sents_train = []\n",
    "sents_test = []\n",
    "for i, sent in enumerate(sentences):\n",
    "    if i <= num_train:\n",
    "        sents_train.append(sent)\n",
    "    else:\n",
    "        sents_test.append(sent)\n",
    "\n",
    "w = open(os.path.join(parent_dir, 'train.txt'), 'w')\n",
    "for sent in sents_train:\n",
    "    for t in sent:\n",
    "        w.write(t + '\\n')\n",
    "    w.write('\\n')\n",
    "w.close()\n",
    "\n",
    "w = open(os.path.join(parent_dir, 'test.txt'), 'w')\n",
    "for sent in sents_test:\n",
    "    for t in sent:\n",
    "        w.write(t + '\\n')\n",
    "    w.write('\\n')\n",
    "w.close()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the files with original labels to new files with regular labels (PER, ORG, LOC, MISC)\n",
    "import os\n",
    "def map_to_regular_ner_tags(input_path, output_path):\n",
    "    f = open(input_path, 'r')\n",
    "    w = open(output_path, 'w')\n",
    "    for l in f:\n",
    "        if l != '\\n':\n",
    "            ner = l[:-1].split(' ')[1]\n",
    "            if 'FIN' in ner or 'PRO' in ner:\n",
    "                word = l[:-1].split(' ')[0]\n",
    "                w.write(word + ' ' + ner[0:2] + 'MISC' + '\\n')\n",
    "            else:\n",
    "                w.write(l)\n",
    "        else:\n",
    "            w.write(l)\n",
    "                \n",
    "    f.close()\n",
    "    w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = os.path.join('with_original_labels', 'all.txt')\n",
    "output_path = os.path.join('all.txt')\n",
    "map_to_regular_ner_tags(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = os.path.join('with_original_labels', 'train.txt')\n",
    "output_path = os.path.join('train.txt')\n",
    "map_to_regular_ner_tags(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = os.path.join('with_original_labels', 'test.txt')\n",
    "output_path = os.path.join('test.txt')\n",
    "map_to_regular_ner_tags(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "q-seg-venv",
   "language": "python",
   "name": "q-seg-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
