{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ner_eval import Evaluator\n",
    "# ref: http://www.davidsbatista.net/blog/2018/05/09/Named_Entity_Evaluation/\n",
    "# Common scenarios in NER evaluation:\n",
    "# Message Understanding Conference (MUC)\n",
    "# MUC introduced detailed metrics in an evaluation considering different categories of errors, ]\n",
    "# these metrics can be defined as in terms of comparing the response of a system against the golden annotation:\n",
    "\n",
    "# Correct (COR) : both are the same;\n",
    "# Incorrect (INC) : the output of a system and the golden annotation don’t match;\n",
    "# Partial (PAR) : system and the golden annotation are somewhat “similar” but not the same;\n",
    "# Missing (MIS) : a golden annotation is not captured by a system;\n",
    "# Spurius (SPU) : system produces a response which doesn’t exit in the golden annotation;\n",
    "\n",
    "# scenario 1: Surface string and entity type match (COR)\n",
    "true1 = ['O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O']\n",
    "pred1 = ['O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O']\n",
    "# scenario 2: System hypothesized an entity (SPU)\n",
    "true2 = ['O', 'O', 'O', 'O', 'O', 'O']\n",
    "pred2 = ['O', 'B-MISC', 'I-MISC', 'O', 'O', 'O']\n",
    "# scenario 3: System misses an entity (MIS)\n",
    "true3 = ['O', 'B-MISC', 'I-MISC', 'O', 'O', 'O']\n",
    "pred3 = ['O', 'O', 'O', 'O', 'O', 'O']\n",
    "# scenario 4: System assigns the wrong entity type (INC)\n",
    "true4 = ['O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O']\n",
    "pred4 = ['O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O']\n",
    "# scenario 5: System gets the boundaries of the surface string wrong (PAR)\n",
    "true5 = ['O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O']\n",
    "pred5 = ['O', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O']\n",
    "# scenario 6: System gets the boundaries and entity type wrong (INC)\n",
    "true6 = ['O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O']\n",
    "pred6 = ['O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O', 'O']\n",
    "\n",
    "\n",
    "true_labels = [true1, true2, true3, true4, true5, true6]\n",
    "pred_labels = [pred1, pred2, pred3, pred4, pred5, pred6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The SemEval’13 introduced four different ways to measure precision/recall/f1-score results \n",
    "# based on the metrics defined by MUC.\n",
    "\n",
    "# Strict (****): exact boundary surface string match and entity type;\n",
    "# Exact (***): exact boundary match over the surface string, regardless of the type;\n",
    "# Type (**): some overlap between the system tagged entity and the gold annotation is required;\n",
    "# Partial (*): partial boundary match over the surface string, regardless of the type;\n",
    "\n",
    "# each of these ways to measure the performance accounts for \n",
    "# correct, incorrect, partial, missed and spurious (as in Message Understanding Conference (MUC)) \n",
    "# in different ways.\n",
    "\n",
    "# scenario 1: Strict (1), Exact (1), Partial (1), Type (1)\n",
    "# scenario 2: Strict (0), Exact (0), Partial (0), Type (0)\n",
    "# scenario 3: Strict (0), Exact (0), Partial (0), Type (0)\n",
    "# scenario 4: Strict (0), Exact (1), Partial (1), Type (0)\n",
    "# scenario 5: Strict (0), Exact (0), Partial (1), Type (1)\n",
    "# scenario 6: Strict (0), Exact (0), Partial (1), Type (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-04 20:30:35 root INFO: Imported 6 predictions for 6 true examples\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator(true_labels, pred_labels, ['LOC', 'MISC', 'PER', 'ORG'])\n",
    "results, results_agg = evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ent_type': {'correct': 3,\n",
       "  'incorrect': 2,\n",
       "  'partial': 0,\n",
       "  'missed': 1,\n",
       "  'spurious': 1,\n",
       "  'possible': 6,\n",
       "  'actual': 6,\n",
       "  'precision': 0.5,\n",
       "  'recall': 0.5,\n",
       "  'f1': 0.5},\n",
       " 'partial': {'correct': 3,\n",
       "  'incorrect': 0,\n",
       "  'partial': 2,\n",
       "  'missed': 1,\n",
       "  'spurious': 1,\n",
       "  'possible': 6,\n",
       "  'actual': 6,\n",
       "  'precision': 0.6666666666666666,\n",
       "  'recall': 0.6666666666666666,\n",
       "  'f1': 0.6666666666666666},\n",
       " 'strict': {'correct': 2,\n",
       "  'incorrect': 3,\n",
       "  'partial': 0,\n",
       "  'missed': 1,\n",
       "  'spurious': 1,\n",
       "  'possible': 6,\n",
       "  'actual': 6,\n",
       "  'precision': 0.3333333333333333,\n",
       "  'recall': 0.3333333333333333,\n",
       "  'f1': 0.3333333333333333},\n",
       " 'exact': {'correct': 3,\n",
       "  'incorrect': 2,\n",
       "  'partial': 0,\n",
       "  'missed': 1,\n",
       "  'spurious': 1,\n",
       "  'possible': 6,\n",
       "  'actual': 6,\n",
       "  'precision': 0.5,\n",
       "  'recall': 0.5,\n",
       "  'f1': 0.5}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for k in results:\n",
    "    p = results[k]['precision']\n",
    "    r = results[k]['recall']\n",
    "    f1 = 2*(p*r)/(p+r) if (p+r)>0 else 0\n",
    "    results[k]['f1'] = f1\n",
    "    \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOC': {'ent_type': {'correct': 1,\n",
       "   'incorrect': 1,\n",
       "   'partial': 0,\n",
       "   'missed': 0,\n",
       "   'spurious': 1,\n",
       "   'possible': 2,\n",
       "   'actual': 3,\n",
       "   'precision': 0.3333333333333333,\n",
       "   'recall': 0.5,\n",
       "   'f1': 0.4},\n",
       "  'partial': {'correct': 2,\n",
       "   'incorrect': 0,\n",
       "   'partial': 0,\n",
       "   'missed': 0,\n",
       "   'spurious': 1,\n",
       "   'possible': 2,\n",
       "   'actual': 3,\n",
       "   'precision': 0.6666666666666666,\n",
       "   'recall': 1.0,\n",
       "   'f1': 0.8},\n",
       "  'strict': {'correct': 1,\n",
       "   'incorrect': 1,\n",
       "   'partial': 0,\n",
       "   'missed': 0,\n",
       "   'spurious': 1,\n",
       "   'possible': 2,\n",
       "   'actual': 3,\n",
       "   'precision': 0.3333333333333333,\n",
       "   'recall': 0.5,\n",
       "   'f1': 0.4},\n",
       "  'exact': {'correct': 2,\n",
       "   'incorrect': 0,\n",
       "   'partial': 0,\n",
       "   'missed': 0,\n",
       "   'spurious': 1,\n",
       "   'possible': 2,\n",
       "   'actual': 3,\n",
       "   'precision': 0.6666666666666666,\n",
       "   'recall': 1.0,\n",
       "   'f1': 0.8}},\n",
       " 'MISC': {'ent_type': {'correct': 0,\n",
       "   'incorrect': 0,\n",
       "   'partial': 0,\n",
       "   'missed': 1,\n",
       "   'spurious': 1,\n",
       "   'possible': 1,\n",
       "   'actual': 1,\n",
       "   'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1': 0},\n",
       "  'partial': {'correct': 0,\n",
       "   'incorrect': 0,\n",
       "   'partial': 0,\n",
       "   'missed': 1,\n",
       "   'spurious': 1,\n",
       "   'possible': 1,\n",
       "   'actual': 1,\n",
       "   'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1': 0},\n",
       "  'strict': {'correct': 0,\n",
       "   'incorrect': 0,\n",
       "   'partial': 0,\n",
       "   'missed': 1,\n",
       "   'spurious': 1,\n",
       "   'possible': 1,\n",
       "   'actual': 1,\n",
       "   'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1': 0},\n",
       "  'exact': {'correct': 0,\n",
       "   'incorrect': 0,\n",
       "   'partial': 0,\n",
       "   'missed': 1,\n",
       "   'spurious': 1,\n",
       "   'possible': 1,\n",
       "   'actual': 1,\n",
       "   'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1': 0}},\n",
       " 'PER': {'ent_type': {'correct': 1,\n",
       "   'incorrect': 1,\n",
       "   'partial': 0,\n",
       "   'missed': 0,\n",
       "   'spurious': 1,\n",
       "   'possible': 2,\n",
       "   'actual': 3,\n",
       "   'precision': 0.3333333333333333,\n",
       "   'recall': 0.5,\n",
       "   'f1': 0.4},\n",
       "  'partial': {'correct': 0,\n",
       "   'incorrect': 0,\n",
       "   'partial': 2,\n",
       "   'missed': 0,\n",
       "   'spurious': 1,\n",
       "   'possible': 2,\n",
       "   'actual': 3,\n",
       "   'precision': 0.3333333333333333,\n",
       "   'recall': 0.5,\n",
       "   'f1': 0.4},\n",
       "  'strict': {'correct': 0,\n",
       "   'incorrect': 2,\n",
       "   'partial': 0,\n",
       "   'missed': 0,\n",
       "   'spurious': 1,\n",
       "   'possible': 2,\n",
       "   'actual': 3,\n",
       "   'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1': 0},\n",
       "  'exact': {'correct': 0,\n",
       "   'incorrect': 2,\n",
       "   'partial': 0,\n",
       "   'missed': 0,\n",
       "   'spurious': 1,\n",
       "   'possible': 2,\n",
       "   'actual': 3,\n",
       "   'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1': 0}},\n",
       " 'ORG': {'ent_type': {'correct': 1,\n",
       "   'incorrect': 0,\n",
       "   'partial': 0,\n",
       "   'missed': 0,\n",
       "   'spurious': 1,\n",
       "   'possible': 1,\n",
       "   'actual': 2,\n",
       "   'precision': 0.5,\n",
       "   'recall': 1.0,\n",
       "   'f1': 0.6666666666666666},\n",
       "  'partial': {'correct': 1,\n",
       "   'incorrect': 0,\n",
       "   'partial': 0,\n",
       "   'missed': 0,\n",
       "   'spurious': 1,\n",
       "   'possible': 1,\n",
       "   'actual': 2,\n",
       "   'precision': 0.5,\n",
       "   'recall': 1.0,\n",
       "   'f1': 0.6666666666666666},\n",
       "  'strict': {'correct': 1,\n",
       "   'incorrect': 0,\n",
       "   'partial': 0,\n",
       "   'missed': 0,\n",
       "   'spurious': 1,\n",
       "   'possible': 1,\n",
       "   'actual': 2,\n",
       "   'precision': 0.5,\n",
       "   'recall': 1.0,\n",
       "   'f1': 0.6666666666666666},\n",
       "  'exact': {'correct': 1,\n",
       "   'incorrect': 0,\n",
       "   'partial': 0,\n",
       "   'missed': 0,\n",
       "   'spurious': 1,\n",
       "   'possible': 1,\n",
       "   'actual': 2,\n",
       "   'precision': 0.5,\n",
       "   'recall': 1.0,\n",
       "   'f1': 0.6666666666666666}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for label in results_agg:\n",
    "    for k in results_agg[label]:\n",
    "        p = results_agg[label][k]['precision']\n",
    "        r = results_agg[label][k]['recall']\n",
    "        f1 = 2*(p*r)/(p+r) if (p+r)>0 else 0\n",
    "        results_agg[label][k]['f1'] = f1\n",
    "\n",
    "results_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qsegmt-venv",
   "language": "python",
   "name": "qsegmt-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
